# CellPLM: Pre-training of Cell Language Model Beyond Single Cells

## Quick Reference
- **Original Paper Location**: [`methodology-and-algorithms/deep-learning-architectures/2024-CellPLM-cell-language-model.md`](../../../methodology-and-algorithms/deep-learning-architectures/2024-CellPLM-cell-language-model.md)
- **Publication**: OpenReview
- **Links**: 
  - Paper: https://openreview.net/forum?id=BKXvPDekud
  - GitHub: https://github.com/OmicsML/CellPLM

## Relevance to Genomics/Transcriptomics
This paper is relevant to genomics/transcriptomics through:
- Novel approach to single-cell RNA-seq data analysis viewing cells as tokens
- Integration of spatial transcriptomics data in pre-training
- Methods for scRNA-seq data denoising
- Spatial transcriptomic data imputation capabilities
- Cell type annotation from transcriptomic data

## Key Points for Transcriptomics Analysis
- First pre-trained model treating cells (rather than genes) as tokens
- Integration of spatial context in transcriptomic analysis
- 100x faster inference compared to existing methods
- Novel approach to handling batch effects in scRNA-seq data

## Notable Results in Transcriptomics
- Superior performance in scRNA-seq data denoising
- Improved spatial transcriptomic imputation
- Effective cell type annotation
- Zero-shot clustering capabilities

## See Also
- Related papers:
  - scGPT: Similar foundation model approach but gene-centric
  - GenePT: A Simple But Effective Foundation Model for Genes and Cells Built From ChatGPT
- Tools: 
  - Spatial transcriptomics analysis platforms
  - Single-cell RNA-seq analysis pipelines
