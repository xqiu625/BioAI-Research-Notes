ğŸ“Š Paper Metadata
* **Title:** scPRINT: pre-training on 50 million cells allows robust gene network predictions
* **Authors:** JÃ©rÃ©mie Kalfon, Jules Samaran, Gabriel PeyrÃ©, Laura Cantini
* **Publication:** bioRxiv (2024, July)
* **Institution:** Institut Pasteur, UniversitÃ© Paris CitÃ©
* **Paper Link:** https://doi.org/10.1101/2024.07.29.605556
* **Code:** https://github.com/cantinilab/scPRINT
* **Tags:** #SingleCell #GeneNetworks #DeepLearning #Transformers #Bioinformatics

ğŸ¯ Core Contributions
1. Developed scPRINT, a foundation model for gene network inference pre-trained on 50M+ cells
2. Novel multi-task pre-training combining denoising, bottleneck learning, and label prediction
3. Superior performance in gene network inference and competitive zero-shot abilities in other tasks
4. New benchmarking suite (BenGRN) for evaluating gene network inference methods

ğŸ“‹ Paper Structure
1. Introduction
* Background: Gene networks represent complex cellular interactions
* Problem: Current methods don't scale well and lack cell-type specificity
* Innovation: Large-scale pre-training on cell atlases with novel architecture

2. Results/Methods
* Novel bidirectional transformer architecture
* Multi-task pre-training strategy
* Extensive benchmarking against existing methods
* Application to prostate cancer analysis

3. Discussion
* Superior performance on network inference
* Competitive performance on auxiliary tasks
* Future applications in cellular biology

ğŸ”¬ Technical Details
Algorithm Framework
1. Core Components:
   * Bidirectional transformer encoder
   * Expression encoder with gene embeddings
   * Zero-inflated negative binomial decoder
   * Multi-task learning system

2. Pre-training Tasks:
   * Denoising via transcript count upsampling
   * Bottleneck learning for cell embeddings
   * Hierarchical label prediction
   
Implementation Details
* Languages: Python
* Key Features: Efficient training (48 hours on A40 GPU)
* Datasets: 50M+ cells from cellxgene database

ğŸ“Š Evaluation
1. Benchmarks:
   * Literature-based networks (Omnipath)
   * Cell type-specific networks
   * Genome-wide perturb-seq data

2. Comparison Methods:
   * GENIE3
   * scGPT
   * Various baseline methods

ğŸ“Œ Key Takeaways
1. First large-scale foundation model specifically for gene network inference
2. Outperforms existing methods on multiple benchmarks
3. Demonstrates utility of multi-task pre-training
4. Practical applicability shown in cancer analysis

## ğŸ’¡ Personal Notes
Implementation Insights
* Novel use of attention mechanisms for network inference
* Efficient scaling strategies for large datasets
* Integration of biological priors in architecture

### A. scPRINT on mouse data:
    1. Processes mouse data through the same pipeline as human data
    2. Successfully benchmarked on mouse embryonic stem cell datasets in the MCalla et al. ground truth evaluations
    3. Uses ESM2 protein embeddings that work across species since proteins are highly conserved between mice and humans

    The model handles mouse genes by:
      - Mapping mouse gene symbols to their protein sequences using Ensembl
      - Converting these into embeddings using ESM2
      - Processing them through the same transformer architecture

    The authors demonstrate this cross-species capability in their benchmarks, showing competitive performance on mouse datasets. This is particularly useful for researchers working with mouse models.

### B. scPRINT's most unique and innovative function:
    1. Cell Type Specificity:
      -  Unlike traditional methods that produce one general network, scPRINT generates networks specific to each cell type or state
      -  Can differentiate between healthy and disease cell states within the same cell type (as shown in their prostate cancer analysis)
      
    2. Implementation Innovation:
      -  Uses a novel "multi-cell attention" mechanism that aggregates information across similar cells
      -  Made computationally efficient enough to handle genome-wide networks (1-100,000 cells) on standard hardware
      -  Can process networks of 2,200 to all expressed genes in a cell
      
    3. Head Selection Method:
      - Introduces a unique way to select relevant attention heads for specific biological contexts
      - Can fine-tune the network generation for different types of interactions (e.g., protein-protein, transcription factor binding)

    4. This functionality is particularly unique because it:
      - Doesn't require additional training (zero-shot)
      - Works across species
      - Scales to genome-wide analysis
      - Maintains biological interpretability
      - Operates on commodity hardware
      
### C. Types of Gene Networks that scPRINT can infer:
      -Gene-to-Gene Interactions
      -Transcription Factor (TF) to Gene relationships
      -Cell type-specific networks
      -Disease-state specific networks



---

# ğŸ¯ æ ¸å¿ƒè´¡çŒ®
1. **å¼€å‘äº† scPRINT**ï¼Œä¸€ä¸ªä¸“ä¸º**åŸºå› ç½‘ç»œæ¨æ–­ï¼ˆGene Network Inferenceï¼‰**è®¾è®¡çš„å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹ï¼ˆfoundation modelï¼‰ï¼Œå¹¶åœ¨**5000ä¸‡+å•ç»†èƒæ•°æ®**ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚
2. **æå‡ºäº†ä¸€ç§æ–°çš„å¤šä»»åŠ¡ï¼ˆmulti-taskï¼‰é¢„è®­ç»ƒç­–ç•¥**ï¼Œç»“åˆ**å»å™ªï¼ˆdenoisingï¼‰**ã€**ç“¶é¢ˆå­¦ä¹ ï¼ˆbottleneck learningï¼‰**å’Œ**æ ‡ç­¾é¢„æµ‹ï¼ˆlabel predictionï¼‰**ã€‚
3. **åœ¨åŸºå› ç½‘ç»œæ¨æ–­æ–¹é¢è¡¨ç°ä¼˜è¶Š**ï¼Œå¹¶ä¸”åœ¨å…¶ä»–ç”Ÿç‰©ä»»åŠ¡ä¸­å±•ç°å‡º**å¼ºå¤§çš„é›¶æ ·æœ¬å­¦ä¹ ï¼ˆzero-shotï¼‰èƒ½åŠ›**ã€‚
4. **æ„å»ºäº†æ–°çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼ˆBenGRNï¼‰**ï¼Œç”¨äºè¯„ä¼°åŸºå› ç½‘ç»œæ¨æ–­æ–¹æ³•çš„æ€§èƒ½ã€‚

---

# ğŸ“‹ è®ºæ–‡ç»“æ„
## 1. å¼•è¨€
- **èƒŒæ™¯ï¼š** åŸºå› è°ƒæ§ç½‘ç»œï¼ˆGene Regulatory Networks, GRNï¼‰æè¿°äº†ç»†èƒå†…å¤æ‚çš„ç›¸äº’ä½œç”¨ã€‚
- **é—®é¢˜ï¼š** ç°æœ‰æ–¹æ³•éš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡æ•°æ®ï¼Œå¹¶ä¸”ç¼ºä¹**ç»†èƒç±»å‹ç‰¹å¼‚æ€§ï¼ˆcell-type specificityï¼‰**ã€‚
- **åˆ›æ–°ç‚¹ï¼š** é‡‡ç”¨**åŸºäº Transformer çš„æ–°æ¶æ„**ï¼Œå¹¶åœ¨å¤§è§„æ¨¡ç»†èƒå›¾è°±ï¼ˆcell atlasesï¼‰ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

## 2. æ–¹æ³•ä¸ç»“æœ
- **é‡‡ç”¨æ–°é¢–çš„åŒå‘ Transformer æ¶æ„**ï¼ˆBidirectional Transformerï¼‰ã€‚
- **æå‡ºå¤šä»»åŠ¡ï¼ˆmulti-taskï¼‰é¢„è®­ç»ƒç­–ç•¥**ï¼ŒåŒ…æ‹¬ï¼š
  1. **å»å™ªï¼ˆDenoisingï¼‰**ï¼šé€šè¿‡è½¬å½•æœ¬ï¼ˆtranscript countsï¼‰ä¸Šé‡‡æ ·æ¥æ¢å¤åŸå§‹åŸºå› è¡¨è¾¾æ•°æ®ã€‚
  2. **ç“¶é¢ˆå­¦ä¹ ï¼ˆBottleneck Learningï¼‰**ï¼šå­¦ä¹ ç»†èƒåµŒå…¥ï¼ˆcell embeddingsï¼‰ï¼Œæå–å…³é”®ç‰¹å¾ã€‚
  3. **å±‚æ¬¡åŒ–æ ‡ç­¾é¢„æµ‹ï¼ˆHierarchical Label Predictionï¼‰**ï¼šé¢„æµ‹ä¸åŒå±‚çº§çš„ç”Ÿç‰©å­¦æ ‡ç­¾ï¼ˆå¦‚ç»†èƒç±»å‹ã€ç–¾ç—…çŠ¶æ€ï¼‰ã€‚
- **åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”**ï¼Œå¹¶å±•ç¤ºå‡ºé¢†å…ˆæ€§èƒ½ã€‚
- **åœ¨å‰åˆ—è…ºç™Œæ•°æ®åˆ†æï¼ˆprostate cancer analysisï¼‰ä¸­å±•ç¤ºå…¶åº”ç”¨ä»·å€¼**ã€‚

## 3. è®¨è®º
- **åœ¨åŸºå› ç½‘ç»œæ¨æ–­ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Š**ã€‚
- **åœ¨è¾…åŠ©ä»»åŠ¡ï¼ˆauxiliary tasksï¼‰ä¸Šä¹Ÿå…·å¤‡ç«äº‰åŠ›**ã€‚
- **æœªæ¥å¯åº”ç”¨äºæ›´å¤šç»†èƒç”Ÿç‰©å­¦ç ”ç©¶**ï¼Œå¦‚ç™Œç—‡ã€å‘è‚²ç”Ÿç‰©å­¦ç­‰ã€‚

---

# ğŸ”¬ æŠ€æœ¯ç»†èŠ‚
## ğŸ“Œ ç®—æ³•æ¡†æ¶
### 1. æ ¸å¿ƒç»„ä»¶
- **åŒå‘ Transformer ç¼–ç å™¨ï¼ˆBidirectional Transformer Encoderï¼‰**
- **åŸºå› è¡¨è¾¾ç¼–ç å™¨ï¼ˆExpression Encoderï¼‰**ï¼Œä½¿ç”¨**åŸºå› åµŒå…¥ï¼ˆGene Embeddingsï¼‰**è¿›è¡Œç‰¹å¾è¡¨ç¤ºã€‚
- **é›¶è†¨èƒ€è´ŸäºŒé¡¹åˆ†å¸ƒè§£ç å™¨ï¼ˆZero-Inflated Negative Binomial Decoder, ZINBï¼‰**ï¼š
  - é€‚ç”¨äº**å•ç»†èƒ RNA-seq æ•°æ®**ï¼Œèƒ½å¤„ç†**é›¶é€šé‡ï¼ˆdropoutï¼‰**é—®é¢˜ã€‚
- **å¤šä»»åŠ¡å­¦ä¹ ç³»ç»Ÿï¼ˆMulti-Task Learning Systemï¼‰**ï¼Œå¯åŒæ—¶è¿›è¡Œå¤šä¸ªä»»åŠ¡ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

### 2. é¢„è®­ç»ƒä»»åŠ¡
- **å»å™ªï¼ˆDenoisingï¼‰ï¼š**é€šè¿‡**ä¸Šé‡‡æ ·è½¬å½•æœ¬è®¡æ•°ï¼ˆupsampling transcript countsï¼‰**æ¢å¤çœŸå®çš„åŸºå› è¡¨è¾¾ã€‚
- **ç“¶é¢ˆå­¦ä¹ ï¼ˆBottleneck Learningï¼‰ï¼š**æå–ç´§å‡‘çš„ç»†èƒè¡¨å¾ï¼ˆcell embeddingsï¼‰ã€‚
- **å±‚æ¬¡åŒ–æ ‡ç­¾é¢„æµ‹ï¼ˆHierarchical Label Predictionï¼‰ï¼š**åŸºäºç»†èƒç±»å‹ã€ç–¾ç—…çŠ¶æ€ç­‰æ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“Œ å®ç°ç»†èŠ‚
- **ç¼–ç¨‹è¯­è¨€ï¼š** Python
- **ä¸»è¦ç‰¹æ€§ï¼š**
  - **é«˜æ•ˆè®­ç»ƒ**ï¼ˆ48å°æ—¶ï¼ŒA40 GPUï¼‰
  - **èƒ½å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ50M+ å•ç»†èƒæ•°æ®ï¼‰**
- **è®­ç»ƒæ•°æ®é›†ï¼š**
  - ä¸»è¦æ¥è‡ª**cellxgene æ•°æ®åº“**ï¼Œæ¶µç›–å¤šç§ç»†èƒç±»å‹ã€‚

---

# ğŸ“Š è¯„ä¼°
## 1. è¯„æµ‹åŸºå‡†ï¼ˆBenchmarksï¼‰
- **æ–‡çŒ®æ”¯æŒçš„åŸºå› ç½‘ç»œï¼ˆOmnipathï¼‰**
- **ç»†èƒç±»å‹ç‰¹å¼‚æ€§ç½‘ç»œï¼ˆCell type-specific networksï¼‰**
- **å…¨åŸºå› ç»„ Perturb-seq æ•°æ®**

## 2. æ¯”è¾ƒæ–¹æ³•
- **GENIE3**
- **scGPT**
- **å…¶ä»–åŸºå‡†æ¨¡å‹**

---

# ğŸ“Œ å…³é”®ç»“è®º
1. **ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºåŸºå› ç½‘ç»œæ¨æ–­çš„å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹ï¼ˆfoundation modelï¼‰ã€‚**
2. **åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚**
3. **è¯æ˜äº†å¤šä»»åŠ¡é¢„è®­ç»ƒï¼ˆmulti-task pre-trainingï¼‰çš„æœ‰æ•ˆæ€§ã€‚**
4. **åœ¨ç™Œç—‡ç ”ç©¶ç­‰ç”Ÿç‰©åº”ç”¨ä¸­å…·æœ‰å®é™…ä»·å€¼ã€‚**

---

# ğŸ’¡ å…³é”®æ¦‚å¿µè§£é‡Š
## A. scPRINT å¦‚ä½•å¤„ç†å°é¼ æ•°æ®ï¼Ÿ
- **scPRINT é‡‡ç”¨ç›¸åŒçš„ç®¡é“å¤„ç†äººç±»å’Œå°é¼ æ•°æ®**ã€‚
- åœ¨å°é¼ æ•°æ®é›†ï¼ˆMCalla et al.ï¼‰çš„çœŸå®æ•°æ®è¯„æµ‹ä¸­ï¼ŒscPRINT å…·æœ‰ç«äº‰åŠ›ã€‚
- ç”±äº**è›‹ç™½åºåˆ—åœ¨å°é¼ å’Œäººç±»ä¹‹é—´å…·æœ‰è¾ƒé«˜çš„ä¿å®ˆæ€§**ï¼ŒscPRINT é‡‡ç”¨ **ESM2 è›‹ç™½åµŒå…¥ï¼ˆESM2 Protein Embeddingsï¼‰** è¿›è¡Œè·¨ç‰©ç§é€‚é…ï¼š
  1. **å°†å°é¼ åŸºå› ç¬¦å·æ˜ å°„åˆ°å…¶è›‹ç™½åºåˆ—**ï¼ˆä½¿ç”¨ Ensembl æ•°æ®åº“ï¼‰ã€‚
  2. **åˆ©ç”¨ ESM2 è®¡ç®—è›‹ç™½åµŒå…¥ï¼ˆembeddingsï¼‰**ã€‚
  3. **å°†å…¶è¾“å…¥ Transformer è¿›è¡Œå¤„ç†**ã€‚

## B. scPRINT çš„æœ€ç‹¬ç‰¹åˆ›æ–°
1. **ç»†èƒç±»å‹ç‰¹å¼‚æ€§ï¼ˆCell Type Specificityï¼‰**
   - ä¼ ç»Ÿæ–¹æ³•åªç”Ÿæˆ**å•ä¸€åŸºå› ç½‘ç»œ**ï¼Œè€Œ scPRINT èƒ½**é’ˆå¯¹ä¸åŒç»†èƒç±»å‹ç”Ÿæˆç‰¹å¼‚æ€§ç½‘ç»œ**ã€‚
   - ç”šè‡³å¯ä»¥åŒºåˆ†**åŒä¸€ç»†èƒç±»å‹ä¸­çš„å¥åº·å’Œç–¾ç—…çŠ¶æ€**ï¼ˆå¦‚å‰åˆ—è…ºç™Œåˆ†æï¼‰ã€‚

2. **æ–°é¢–çš„ "å¤šç»†èƒæ³¨æ„åŠ›ï¼ˆMulti-cell Attentionï¼‰" æœºåˆ¶**
   - **èšåˆç±»ä¼¼ç»†èƒçš„ä¿¡æ¯**ï¼Œæé«˜åŸºå› ç½‘ç»œæ¨æ–­çš„å‡†ç¡®æ€§ã€‚
   - **è®¡ç®—æ•ˆç‡é«˜**ï¼Œå¯åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šè¿è¡Œå…¨åŸºå› ç»„åˆ†æï¼ˆ1-100,000 ç»†èƒï¼‰ã€‚

3. **æ³¨æ„åŠ›å¤´ï¼ˆAttention Headï¼‰é€‰æ‹©æœºåˆ¶**
   - å…è®¸é’ˆå¯¹ä¸åŒçš„ç”Ÿç‰©å­¦é—®é¢˜**é€‰æ‹©æœ€ç›¸å…³çš„æ³¨æ„åŠ›å¤´**ï¼Œå¢å¼ºå¯è§£é‡Šæ€§ã€‚

## C. scPRINT èƒ½æ¨æ–­å“ªäº›ç±»å‹çš„åŸºå› ç½‘ç»œï¼Ÿ
- **åŸºå› -åŸºå› ç›¸äº’ä½œç”¨ï¼ˆGene-to-Gene Interactionsï¼‰**
- **è½¬å½•å› å­-åŸºå› è°ƒæ§ç½‘ç»œï¼ˆTranscription Factor to Geneï¼‰**
- **ç»†èƒç±»å‹ç‰¹å¼‚æ€§ç½‘ç»œï¼ˆCell Type-Specific Networksï¼‰**
- **ç–¾ç—…çŠ¶æ€ç‰¹å¼‚æ€§ç½‘ç»œï¼ˆDisease-State Specific Networksï¼‰**

---

# ğŸ“Œ æ€»ç»“
scPRINT æ˜¯ç¬¬ä¸€ä¸ª**ä¸“æ³¨äºåŸºå› ç½‘ç»œæ¨æ–­çš„åŸºç¡€æ¨¡å‹**ï¼Œç»“åˆ**Transformer+å¤šä»»åŠ¡å­¦ä¹ **ï¼Œåœ¨å¤§è§„æ¨¡**å•ç»†èƒæ•°æ®**ä¸Šè®­ç»ƒï¼Œèƒ½ç”Ÿæˆ**ç»†èƒç±»å‹ç‰¹å¼‚æ€§ç½‘ç»œ**ï¼Œå¹¶åœ¨**ç™Œç—‡ç­‰ç ”ç©¶é¢†åŸŸ**å±•ç°å‡ºå®é™…åº”ç”¨ä»·å€¼ã€‚ğŸš€
